# 聊天模型（Chat Models）

聊天模型（Chat Models）是LangChain的核心组件。

LangChain并不提供自己的ChatModels，而是提供了与许多不同模型进行交互的标准接口。具体来说，这个接口接受一个消息列表作为输入，并返回一个消息。

有很多模型提供商（OpenAI、Cohere、Hugging Face等）- ChatModel类旨在为它们提供一个标准接口。

## [快速入门](/docs/modules/model_io/chat/quick_start)

查看[这个快速入门](/docs/modules/model_io/chat/quick_start)，了解如何使用ChatModels，并了解它们提供的所有不同方法。

## [集成](/docs/integrations/chat/)

要查看LangChain提供的所有LLM集成的完整列表，请转到[集成页面](/docs/integrations/chat/)。

## 操作指南

我们提供了几个关于LLM更高级用法的指南，包括：

- [如何缓存ChatModel响应](/docs/modules/model_io/chat/caching)
- [如何从ChatModel流式传输响应](/docs/modules/model_io/chat/streaming)
- [如何进行函数调用](/docs/modules/model_io/chat/function_calling)

