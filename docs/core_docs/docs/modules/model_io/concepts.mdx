---
sidebar_position: 1
---
# 概念

任何语言模型应用程序的核心要素是... 模型本身。LangChain为您提供了与任何语言模型进行接口的构建模块。本节中的所有内容都是为了更轻松地使用模型。这主要涉及到对模型的清晰接口，用于构建模型输入的辅助工具，以及用于处理模型输出的辅助工具。


## Models（模型）

LangChain与两种主要类型的模型集成：LLMs（Large Language Models）和Chat Models（聊天模型）。这些模型由它们的输入和输出类型定义。


### LLM

LangChain 中的 LLM 指的是纯文本补全模型。
它们包装的 API 将字符串提示作为输入并输出字符串补全。OpenAI的GPT-3就是一个LLM的实现。

### Chat Models

Chat Models通常由LLMs支持，但专门针对进行对话而进行调整。关键是，它们的提供者API使用的接口与纯文本完成模型不同。它们不是接受单个字符串作为输入，而是接受一系列聊天消息作为输入，并返回一个AI消息作为输出。有关消息的确切内容，请参阅下面的部分以获取更多详细信息。GPT-4和Anthropic的Claude-2都是作为聊天模型实现的。


### 注意事项


这两种API类型具有相当不同的输入和输出模式。这意味着与它们互动的最佳方式可能会有很大的不同。尽管LangChain使得可以互换使用它们，但这并不意味着您`应该`这样做。特别是，LLMs和ChatModels的提示策略可能会有很大不同。这意味着您需要确保所使用的提示是针对您正在使用的模型类型设计的。

此外，并非所有模型都相同。不同的模型具有最适合它们的不同提示策略。例如，Anthropic的模型最适合使用XML，而OpenAI的模型最适合使用JSON。这意味着您用于一个模型的提示可能不适用于其他模型。LangChain提供了许多默认提示，但不能保证这些提示在您使用的模型上表现良好。从历史上看，大多数提示在OpenAI上表现良好，但在其他模型上并没有进行过严格测试。这是我们正在努力解决的问题，但这是您应该牢记的事情。


## Messages（消息）

ChatModels 接受一个消息列表作为输入，并返回一个消息。消息有几种不同的类型。所有Messages都具有 `role` 和 `content` 属性。`role` 描述了谁在说这条消息。LangChain 为不同的角色提供了不同的消息类。`content` 属性描述了消息的内容。这可以是几种不同的东西：

- 一个字符串（大多数模型都是这种方式）
- 字典列表（这用于多模态输入，其中字典包含有关该输入类型和该输入位置的信息）

此外，消息有一个 `additional_kwargs` 属性。这是传递关于消息的附加信息的地方。这主要用于 *提供商特定* 的输入参数，而不是一般性的参数。其中一个最知名的示例是来自 OpenAI的 的 `function_call`。

### HumanMessage

这表示来自用户的消息。通常只包含内容。

### AIMessage

这代表来自模型的消息。它可能包含 `additional_kwargs(额外的参数)` - 例如，如果使用 OpenAI 函数调用，可能会包含 `function_call`。

### SystemMessage （系统消息）

这代表了一个系统消息。只有一些模型支持这个功能。这告诉了模型如何行动。通常，它只包含内容。

### FunctionMessage （函数消息）

这代表函数调用的结果。除了 `role` 和 `content` 之外，这个消息还有一个 `name` 参数，表示调用产生此结果的函数的名称。

### ToolMessage （工具消息）

这表示工具调用的结果。这与`FunctionMessage`不同，以匹配OpenAI的 `function`和`tool`消息类型。除了`role`和`content`之外，此消息还具有一个`tool_call_id`参数，用于传递产生此结果的工具调用的id。


## Prompts （提示）

语言模型的输入通常称为提示。通常情况下，您应用程序中的用户输入并不直接作为模型的输入。相反，他们的输入以某种方式进行转换，以产生最终输入模型的字符串或消息列表。负责接收用户输入并将其转换为最终字符串或消息的对象称为“Prompt Templates”。LangChain提供了几种抽象来简化处理提示的工作。


### PromptValue （提示值）

ChatModels和LLMs接受不同的输入类型。PromptValue是一个设计用于在这两者之间进行互操作的类。它提供了一个方法将其转换为字符串（用于与LLMs一起使用），另一个方法将其转换为消息列表（用于与ChatModels一起使用）。

### PromptTemplate （提示词模板）

这是一个提示模板的示例。它包含一个模板字符串。然后，该字符串与用户输入进行格式化，以生成最终的字符串。

### MessagePromptTemplate （消息提示模板）
这是一个提示模板的示例。它包含一个模板**消息** - 意味着一个特定的角色和一个PromptTemplate。然后，该 PromptTemplate 与用户输入进行格式化，以生成最终的字符串，成为此消息的`content`。

#### HumanMessagePromptTemplate

这是一个产生 HumanMessage 的 MessagePromptTemplate。

#### AIMessagePromptTemplate

这是一个产生 AIMessage 的 MessagePromptTemplate。

#### SystemMessagePromptTemplate 

这是一个产生 SystemMessage 的 MessagePromptTemplate。

### MessagesPlaceholder （消息占位符）

通常，提示的输入可以是一系列消息。这时你会使用 MessagesPlaceholder。这些对象通过一个 `variable_name` 参数来参数化。
与该`variable_name`值相同的输入应该是一个消息列表

### ChatPromptTemplate （聊天提示模板）

这是一个提示模板的例子。它由一系列 MessagePromptTemplates 或 MessagePlaceholders 组成。然后这些模板与用户的输入格式化，以生成最终的消息列表。



## Output Parsers （输出解析器）

模型的输出要么是字符串，要么是消息。通常情况下，字符串或消息包含以特定格式格式化的信息，以供下游使用（例如，逗号分隔的列表或JSON 快）。输出解析器负责接收模型的输出并将其转换为更可用的形式。通常情况下，它们操作输出消息的`content` ，但偶尔也会操作`additional_kwargs`字段中的值。



### StrOutputParser （字符串输出解析器）

这是一个简单的输出解析器，它只是将语言模型（LLM 或 ChatModel）的输出转换为字符串。如果模型是 LLM（因此输出一个字符串），它只是传递这个字符串。如果输出是 ChatModel（因此输出一个消息），它就传递消息的 `.content` 属性。

### OpenAI Functions Parsers （OpenAI 函数解析器）

有一些解析器专门用于处理 OpenAI 函数调用。它们获取 `function_call` 和 `arguments` 参数的输出（这些参数位于 `additional_kwargs` 中），并与其一起工作，主要忽略内容。

### Agent Output Parsers （代理输出解析器）

[代理](../agents)是使用语言模型确定要采取哪些步骤的系统。因此，语言模型的输出需要被解析成能够表示要采取的行动（如果有的话）的某种模式。AgentOutputParsers负责接收原始LLM或ChatModel输出，并将其转换为该模式。这些输出解析器内部的逻辑可能会根据所使用的模型和提示策略而有所不同。


